\documentclass{sig-alternate}

\usepackage[utf8]{inputenc}
\usepackage[hyphens]{url}
\usepackage[pdftex,urlcolor=black,colorlinks=true,linkcolor=black,citecolor=black]{hyperref}

% listings and Verbatim environment
\usepackage{fancyvrb}
\usepackage{relsize}
\usepackage{listings}
\usepackage{verbatim}
\newcommand{\defaultlistingsize}{\fontsize{8pt}{9.5pt}}
\newcommand{\inlinelistingsize}{\fontsize{8pt}{11pt}}
\newcommand{\smalllistingsize}{\fontsize{7.5pt}{9.5pt}}
\newcommand{\listingsize}{\defaultlistingsize}
\RecustomVerbatimCommand{\Verb}{Verb}{fontsize=\inlinelistingsize}
\RecustomVerbatimEnvironment{Verbatim}{Verbatim}{fontsize=\defaultlistingsize}
\lstset{frame=lines,captionpos=b,numberbychapter=false,escapechar=§,
        aboveskip=2em,belowskip=1em,abovecaptionskip=0.5em,belowcaptionskip=0.5em,
        framexbottommargin=-1em,basicstyle=\ttfamily\listingsize\selectfont}

% use Courier from this point onward
\let\oldttdefault\ttdefault
\renewcommand{\ttdefault}{pcr}
\let\oldurl\url
\renewcommand{\url}[1]{\inlinelistingsize\oldurl{#1}}

\lstdefinelanguage{JavaScript}{
  keywords={push, typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{darkgray},
  stringstyle=\color{red},
  morestring=[b]',
  morestring=[b]"
}

% linewrap symbol
\usepackage{color}
\definecolor{grey}{RGB}{130,130,130}
\newcommand{\linewrap}{\raisebox{-.6ex}{\textcolor{grey}{$\hookleftarrow$}}}

\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{International World Wide Web Conference}{2014 Seoul, Korea}
\CopyrightYear{2014} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Read/Write Semantic and Representational Online Video Annotation by Leveraging WebVTT and JSON-LD}

\numberofauthors{6}

\author{
% 1st. author
\alignauthor
Thomas Steiner\titlenote{Thomas Steiner's second affiliation is \emph{T.~Steiner, Google Germany GmbH, ABC-Str.~19, 20354 Hamburg, Germany}}\\
       \affaddr{Université de Lyon} 
       \affaddr{CNRS Université Lyon~1}\\
       \affaddr{LIRIS, UMR5205}\\
       \affaddr{F-69622 France}\\
       \email{tsteiner@liris.cnrs.fr}
% 2nd. author
\alignauthor
Pierre-Antoine Champin\\
       \affaddr{Université de Lyon} 
       \affaddr{CNRS Université Lyon~1}\\
       \affaddr{LIRIS, UMR5205}\\
       \affaddr{F-69622 France}\\
       \email{champin@liris.cnrs.fr}
% 3rd. author
\alignauthor
Benoît Encelle\\
       \affaddr{Université de Lyon} 
       \affaddr{CNRS Université Lyon~1}\\
       \affaddr{LIRIS, UMR5205}\\
       \affaddr{F-69622 France}\\
       \email{encelle@liris.cnrs.fr}
\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor
Yannick Prié\\
       \affaddr{Université de Nantes}\\
       \affaddr{LINA - UMR 6241}\\
       \affaddr{CNRS, France}\\
       \email{yannick.prie@univ-nantes.fr}
% 5th. author
\alignauthor
Ruben Verborgh\\
       \affaddr{Ghent University}\\
       \affaddr{iMinds -- Multimedia Lab}\\
       \affaddr{G.~Crommenlaan~8 bus~201}\\
       \affaddr{9050~Ghent, Belgium}\\
       \email{ruben.verborgh@ugent.be}
% 6th. author
\alignauthor
Rik Van de Walle\\
       \affaddr{Ghent University}\\
       \affaddr{iMinds -- Multimedia Lab}\\
       \affaddr{G.~Crommenlaan~8 bus~201}\\       
       \affaddr{9050~Ghent, Belgium}\\
       \email{rik.vandewalle@ugent.be}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
In this paper, we present and evaluate
a~video annotation model and related technology stack
wholly based on HTML5 Web standards
and optimally leveraging native functionality
already present in modern Web browsers,
which together allows for fully Read/Write-enabled
semantic and representational video annotations.
At video consumption time, such video annotations
can already be existent as is the case
with annotations created by the video producer
(\emph{i.e.},~annotations of type \emph{Read}),
equally well as be created on-the-fly by the video consumer
(\emph{i.e.},~annotations of type \emph{Write}).
Our video annotation model allows for both,
semantic and representational annotations.
Semantic annotations are related to meaning in videos,
whereas representational annotations are related to
ways in which videos get represented to the viewer.
We evaluate our technology stack and annotation model
based on a~state-of-the-art hypervideo model.
\end{abstract}

\category{H.4}{Information Systems Applications}{Miscellaneous}
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Theory}

\keywords{video annotation}

\section{Introduction}

\section{Related Work}

\cite{vandeursen2012mediafragmentannotations}

\section{Enabling Technologies}

\subsection{Web Video Text Tracks format (WebVTT)}

The Web Video Text Tracks format (WebVTT,~\cite{pfeiffer2013webvtt})
is intended for marking up external text track resources mainly
for the purpose of captioning video content.
The recommended file extension is \texttt{vtt},
the MIME type is \texttt{text/vtt}.
WebVTT files are encoded in UTF-8 and
start with the required string \texttt{WEBVTT}.
Each file consists of items called \emph{cues}
that are separated by an empty line.
Each cue has a~start time and an end time in
\texttt{hh:mm:ss.milliseconds} format,
separated by a~stylized ASCII arrow \texttt{-}\texttt{->}.
The cue payload follows in the line after the cue timings part
and can span multiple lines.
Typically, the cue payload contains text,
but can also contain textual data serialization formats like JSON,
which later on in the paper we will show to be essential
for the proposed approach of semantic video annotation.
Spans of text associated with a~specific voice can be annotated
in form of WebVTT cue voice spans.
A WebVTT voice tag, denoted by \texttt{<v VOICE>}, has a~value,
which is the name of the voice.
Cues can optionally have unique IDs
followed by a~colon in the line
above the cue timings part.
\autoref{listing:webvtt} shows an exemplary WebVTT file.

\begin{lstlisting}[caption={Sample WebVTT file with two cues
    with the IDs \texttt{cue-vincent} and
    \texttt{cue-jules} respectively},
  label=listing:webvtt, float=h!]
WEBVTT

cue-vincent:
00:07:55.185 --> 00:08:00.247
<v Vincent>And you know what they call
a Quarter-Pounder with Cheese in Paris?

cue-jules:
00:08:00.290 --> 00:08:01.917
<v Jules>They don't call it
a Quarter-Pounder with Cheese?
\end{lstlisting}

\subsubsection{WebVTT in Web Browsers}

Compliant Web browsers~\cite{dutton2012trackelement}
support five different kinds of
WebVTT text tracks, specified by HTML5~\cite{berjon2013html5}
and listed in \autoref{table:texttrackkinds}.
In this paper, we especially focus on
text tracks of kind \texttt{metadata}
that are meant to be used from JavaScript and
that are not displayed by the user agent.

Both the HTML5 \texttt{<audio>} and \texttt{<video>} elements
have a~\texttt{textTracks} property
that returns a~\texttt{TextTrackList} of
\texttt{TextTrack} members, each of which correspond
to individual <track> elements.
A~\texttt{TextTrack} has a~\texttt{cues} property
that returns a~\texttt{TextTrackCueList} of individual
\texttt{TextTrackCue} items.
Cue data is accessible via properties like
\texttt{startTime}, \texttt{endTime} and,
most importantly, \texttt{text} to obtain a~cue's payload.
When the payload is in JSON format,
it can be parsed and made programmatically usable via the
\texttt{JSON.parse(cue.text)} function.

When a~media resource like a~video or audio is playing,
JavaScript events of the \texttt{TextTrack} and \texttt{TextTrackCue}
elements fire automatically when the \texttt{currentPosition}
of the media resource matches the
\texttt{startTime} or \texttt{endTime} of a~cue.
\texttt{TextTrack} elements fire \texttt{oncuechange} events,
whereas \texttt{TextTrackCue} elements fire
\texttt{onenter} and \texttt{onexit} events.
JavaScript applications can subscribe to these events
by adding event listeners to the elements in question.
Both \texttt{TextTrack} and \texttt{TextTrackCue} elements
can also be dynamically generated by JavaScript applications.

\begin{table*}[h!]\footnotesize
\begin{tabular}{ r p{15cm} }
\textbf{WebVTT Kind} & \textbf{Description}\\

\texttt{subtitles} & Transcription or translation of the dialogue,
suitable for when the sound is available but not understood
(\emph{e.g.}, when the user does not understand the language). Overlaid on the video.\\

\texttt{captions} & Transcription or translation of the dialogue,
sound effects, relevant musical cues,
and other relevant audio information,
suitable for when sound is unavailable or not clearly audible
(\emph{e.g.}, when the user is deaf). Overlaid on the video;
labeled as appropriate for the hard-of-hearing.\\

\texttt{descriptions} & Textual descriptions of the video component
of the media resource, intended for audio synthesis
when the visual component is obscured, unavailable, or unusable
(\emph{e.g.}, when the user is blind).
Synthesized as audio.\\

\texttt{chapters} & Chapter titles, intended to be used for navigating
the media resource. Displayed as an interactive (potentially nested)
list in the user agent's interface.\\

\texttt{metadata} & Tracks intended for programmatic use from script.
Not displayed by the user agent.\\
\end{tabular}
  \caption{Different WebVTT text track kinds as specified by
    HTML5~\cite{berjon2013html5}}
  \label{table:texttrackkinds}
\end{table*}

\subsection{JSON-LD}

The \emph{JavaScript Object Notation}
(JSON\footnote{\url{http://json.org/}})
is a~(by now) language-independent textual syntax
for serializing objects, arrays, numbers, strings, booleans, and null.
\emph{Linked Data}~\cite{bizer2009linkeddata}
describes a~method of publishing structured data
so that it can be interlinked and become more useful,
which builds upon standard Web technologies such as HTTP, RDF and URIs.
Based on top of JSON, the
\emph{JavaScript Object Notation for Linked Data}
(JSON-LD,~\cite{sporny2013jsonld}) is a~method for transporting
Linked Data with a~smooth upgrade path from JSON to JSON-LD.
It is primarily intended to be a~way to use
Linked Data in Web-based programming environments,
to build interoperable Web services,
and to store Linked Data in JSON-based storage engines.
We use JSON-LD as payload of \texttt{TextTrackCue} elements.

\subsection{Media Fragments URI}

Media Fragments URI~\cite{troncy2012mediafragments}
specifies a~syntax for constructing media fragments URIs
and explains how to handle them when used over the HTTP protocol.
The syntax is based on the specification of
particular name-value pairs that can be used in URI query strings
and URI fragment identifiers to restrict a~media resource
to a~certain fragment.
Media Fragments as described in the basic version
of the specification supports temporal and spatial media fragments.
The \emph{temporal dimension} is denoted
by the parameter name \texttt{t} and specified as an interval
with a~begin time and an end time.
Either one or both parameters may be omitted,
with the begin time defaulting to 0 seconds
and the end time defaulting to the duration of the source media item.
The interval is half-open: the begin time is considered
part of the interval, whereas the end time is considered
to be the first time point that is not part of the interval.
The \emph{spatial dimension} selects
an area of pixels from media items.
In the current version of the specification,
only rectangular selections are supported.
Rectangles can be specified as pixel coordinates or percentages.
Rectangle selection is denoted by the parameter name \texttt{xywh}.
The value is either \texttt{pixel:} or \texttt{percent:}
(defaulting to \texttt{pixel:}) and four comma-separated integers.
The integers denote $x$, $y$, $width$, and $height$ respectively,
with $x = 0$ and $y = 0$ being the top left corner of the media item.
If \texttt{percent:} is used, $x$ and $width$ are interpreted
as a~percentage of the width of the original media item,
$y$ and $height$ are interpreted as a~percentage
of the original height.

The Ontology for Media Resources~\cite{lee2012mediaontology}
serves to bridge different description methods of media resources
and to provide a~core set of descriptive properties.
Combined with Media Fragments URI,
this allows for making statements about media items
and fragments thereof.

\section{Hypervideo}

In~\cite{sadallah2012hypervideo}, Sadallah \emph{et~al.}\ define
\emph{hypervideo} as being \textit{``an interactive video-centric
hypermedia document built upon audiovisual content''}.
The authors identify three common hypervideo characteristics,
namely \emph{(i)}~\emph{interactivity}, which, \emph{e.g.},
can enable richer navigational possibilities, 
\emph{(ii)}~\emph{non-linearity}, which allows for advanced features
like video montages, and finally \emph{(iii)}~\emph{enrichments}
that include all sorts of supplementary material besides
and on top of hypervideos.
Sadallah \emph{et~al.}\ have examined hypervideo systems
of the recent years and found a~number of
recurring visualization and interaction patterns
that we will summarize in the following.

\begin{description}
  \item[Video player and controls:]  \item[Timeline:]  \item[Textual overlay:]  \item[Graphical overlay:]  \item[Hotspot:]  \item[ToC:]
  \item[Maps:]  \item[Transcript:]
\end{description}  
  
\section{Evaluation and Discussion}

\section{Future Work and Conclusions}

\section*{Acknowledgments}

The research presented in this paper
was partially supported by the ANR project
\emph{Spectacle En Ligne(s)}, project reference
\mbox{ANR-12-CORP-0015}.

\bibliographystyle{abbrv}
\bibliography{references}

\end{document}